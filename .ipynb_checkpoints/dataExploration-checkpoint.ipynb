{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "arabic-greek",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly_express'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f6fbcf9a608f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mplotly_express\u001b[0m  \u001b[1;32mas\u001b[0m \u001b[0mpx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ignore'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'plotly_express'"
     ]
    }
   ],
   "source": [
    "# merging books1-100k and apibooks3 ON isbn = ISBN\n",
    "# then do analysis on merged file using techniques from 2 different sites\n",
    "\n",
    "import requests\n",
    "import csv\n",
    "import urllib\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "%matplotlib inline\n",
    "import plotly_express  as px\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from scipy.stats import norm\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thick-entrance",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('cleaned_book1-100k.csv')\n",
    "df2 = pd.read_csv('cleaned_apiBooks3.csv')\n",
    "\n",
    "df1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "warming-mirror",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "necessary-qualification",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "domestic-absolute",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statewide-steam",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaggle exploration - https://www.kaggle.com/melikedemirdag/goodbooks-10k-visualization\n",
    "# Top 10 books in bar graph\n",
    "# this is coming from book1-100k\n",
    "df1 = pd.read_csv('TravisStuff/cleaned_book1-100k.csv')\n",
    "top_rated = df1[(df1['RatingDistTotal'] > 100)]\n",
    "top_rated = top_rated.sort_values(by=['Rating', 'RatingDistTotal'], ascending = False)\n",
    "\n",
    "tf_top_rated = top_rated[0:1]\n",
    "tf_top_rated = tf_top_rated.append(top_rated[3:6])\n",
    "tf_top_rated = tf_top_rated.append(top_rated[7:13])\n",
    "\n",
    "fig = px.bar(tf_top_rated, x=\"Rating\", y=\"Name\", title='Top 10 Rated Books with >100 Reviews',\n",
    "             orientation='h', width=1500, height=700)\n",
    "fig.show()\n",
    "fig.write_image('TopRatedBooks.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "underlying-philip",
   "metadata": {},
   "source": [
    "#### distribution of average ratings of all the 10000 books\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.title(\"Distribution of Average Ratings\")\n",
    "df1[\"Rating\"].hist()\n",
    "display()\n",
    "plt.savefig('AvgRatingsDistribution.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "valuable-services",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Most frequently-reviewed authors\n",
    "top_author_counts = df1['Authors'].value_counts().reset_index()\n",
    "top_author_counts.columns = ['value', 'count']\n",
    "top_author_counts['value'] = top_author_counts['value']\n",
    "top_author_counts = top_author_counts.sort_values('count')\n",
    "fig = px.bar(top_author_counts.tail(10), x=\"count\", y=\"value\", title='Top Authors', orientation='h', color='value',\n",
    "             width=1000, height=700)\n",
    "fig.show()\n",
    "fig.write_image('MostFrequentAuthors.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compliant-bhutan",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of Year Published\n",
    "years= df1['PublishYear'].value_counts().reset_index()\n",
    "years.columns = ['year', 'count']\n",
    "years['year'] = years['year']\n",
    "years = years.sort_values('count')\n",
    "fig = px.bar(years.tail(50), x=\"count\", y=\"year\", title='Publication Year', orientation='h', color='count',\n",
    "             width=1000, height=700)\n",
    "fig.show()\n",
    "fig.write_image('DistofPublishYr.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "animated-enlargement",
   "metadata": {},
   "outputs": [],
   "source": [
    "# start of second link - https://medium.com/analytics-vidhya/do-you-love-reading-lets-use-data-mining-and-find-some-good-reads-for-you-e5bf1b576316\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "revised-trace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# following attributes are numerical i.e. float or int types: \n",
    "# pages, PublishMonth, PublishDay, CountsOfReview, PublishYear, Rating\n",
    "# day and month are backwards fyi\n",
    "continuousVars = ['pagesNumber','CountsOfReview','PublishYear', 'Rating']\n",
    "df1[continuousVars].describe().to_csv('NumericAttributesInfo.csv')\n",
    "df1[continuousVars].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-registration",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize = (20,25))\n",
    "ax = fig.gca()\n",
    "blah = result['PublishYear'].hist(ax = ax)\n",
    "plt.show()\n",
    "# didn't bother saving any of these\n",
    "# some are duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southwest-cement",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Think it would be nice to draw a normal curve on the histograms to check out the skewness of the data distribution.\n",
    "def PlotHistogramsWithNormalCurve(dfCol, varName, bins=20, color='b'):\n",
    "    dMean, dStd = norm.fit(dfCol)\n",
    "    plt.figure(figsize = (8, 8))\n",
    "    # Plot hist\n",
    "    plt.hist(dfCol, bins, density=True, alpha=0.6, color=color)\n",
    "    # Plot PDF.\n",
    "    xmin, xmax = plt.xlim()\n",
    "    xlin = np.linspace(xmin, xmax, 100)\n",
    "    pdf = norm.pdf(xlin, dMean, dStd)\n",
    "    plt.plot(xlin, pdf, 'k', linewidth=2)\n",
    "    title = \"Fit results for [\" + varName + \"]: Mean = %.4f,  Std. Dev, = %.4f\" % (dMean, dStd)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "    \n",
    "PlotHistogramsWithNormalCurve(df1['PublishYear'], \"Year Published\")\n",
    "plt.savefig('YrPublishedWithNormalCurve.jpg')\n",
    "\n",
    "PlotHistogramsWithNormalCurve(result['Rating'], \"Ratings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indoor-relations",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the same function as above, but I modified it so that I could print the plot\n",
    "dMean, dStd = norm.fit(df1['PublishYear'])\n",
    "plt.figure(figsize = (8, 8))\n",
    "# Plot hist\n",
    "plt.hist(df1['PublishYear'], 20, density=True, alpha=0.6, color='b')\n",
    "# Plot PDF.\n",
    "xmin, xmax = plt.xlim()\n",
    "xlin = np.linspace(xmin, xmax, 100)\n",
    "pdf = norm.pdf(xlin, dMean, dStd)\n",
    "plt.plot(xlin, pdf, 'k', linewidth=2)\n",
    "title = \"Fit results for [\" + \"Year Published\" + \"]: Mean = %.4f,  Std. Dev, = %.4f\" % (dMean, dStd)\n",
    "plt.title(title)\n",
    "display()\n",
    "plt.savefig('YrPublishedWithNormalCurve.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overhead-mexican",
   "metadata": {},
   "outputs": [],
   "source": [
    "# redoing for rating\n",
    "dMean, dStd = norm.fit(df1['Rating'])\n",
    "plt.figure(figsize = (8, 8))\n",
    "# Plot hist\n",
    "plt.hist(df1['Rating'], 20, density=True, alpha=0.6, color='b')\n",
    "# Plot PDF.\n",
    "xmin, xmax = plt.xlim()\n",
    "xlin = np.linspace(xmin, xmax, 100)\n",
    "pdf = norm.pdf(xlin, dMean, dStd)\n",
    "plt.plot(xlin, pdf, 'k', linewidth=2)\n",
    "title = \"Fit results for [\" + \"Avg. Ratings\" + \"]: Mean = %.4f,  Std. Dev, = %.4f\" % (dMean, dStd)\n",
    "plt.title(title)\n",
    "display()\n",
    "plt.savefig('AvgRatingsWithNormalCurve.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial-alpha",
   "metadata": {},
   "outputs": [],
   "source": [
    "# box plots to check for outliers\n",
    "plt.figure(figsize = (10, 10))\n",
    "df1.boxplot(column= ['pagesNumber','CountsOfReview','PublishYear', 'Rating'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-argument",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shrink scale to see on same scale\n",
    "df3 = df1[(df1['CountsOfReview'] < 10000)]\n",
    "plt.figure(figsize = (10, 10))\n",
    "df3.boxplot(column= ['pagesNumber','CountsOfReview','PublishYear', 'Rating'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "featured-commons",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shrink scale to see on same scale\n",
    "df4 = df1[(df1['CountsOfReview'] < 4000)]\n",
    "plt.figure(figsize = (10, 10))\n",
    "df4.boxplot(column= ['pagesNumber','CountsOfReview','PublishYear', 'Rating'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "paperback-cholesterol",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is actually normalizing variables\n",
    "\n",
    "# Create varsToNormalize, where all the varsToNormalize values are treated as floats\n",
    "varsToNormalize = df1[['pagesNumber','CountsOfReview','PublishYear', 'Rating']].values.astype(float)\n",
    "\n",
    "# Create a minimum and maximum preprocessing object\n",
    "range_Scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "# Create an object to transform the data to fit minmax processor\n",
    "vars_Scaled = range_Scaler.fit_transform(varsToNormalize)\n",
    "\n",
    "# Run the normalizer on the dataframe\n",
    "df_normalized = pd.DataFrame(vars_Scaled)\n",
    "\n",
    "plt.figure(figsize = (10, 10))\n",
    "df_normalized.boxplot()\n",
    "display()\n",
    "plt.savefig('BoxPlots.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rational-somerset",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forward-bolivia",
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricalVars = ['Name', 'Publisher', 'Authors']\n",
    "df1[categoricalVars].describe().to_csv('CategoricalSummary.csv')\n",
    "df1[categoricalVars].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "extended-departure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Books with most ratings\n",
    "\n",
    "top10Books = df1.nlargest(10, ['CountsOfReview']).set_index('Name')['CountsOfReview']\n",
    "plot_dims = (30, 8)\n",
    "fig, ax = plt.subplots(figsize=plot_dims)\n",
    "sns.barplot(top10Books, top10Books.index)\n",
    "\n",
    "for i in ax.patches:\n",
    "    ax.text(i.get_width()+.3, i.get_y()+0.5, str(round(i.get_width())), fontsize = 15, color = 'k')\n",
    "    \n",
    "display()\n",
    "plt.savefig('MostRatedBooks.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "starting-bandwidth",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-avatar",
   "metadata": {},
   "outputs": [],
   "source": [
    "#distribution of description lengths\n",
    "dfx = []\n",
    "i=0\n",
    "j=0\n",
    "k=0\n",
    "l=0\n",
    "m=0\n",
    "n=0\n",
    "o=0\n",
    "p=0\n",
    "q=0\n",
    "r=0\n",
    "s=0\n",
    "t=0\n",
    "u=o\n",
    "for x in df2['synopsys']:\n",
    "    if len(x)>=0 and len(x)<250:\n",
    "        i=i+1\n",
    "    if len(x)>=250 and len(x)<500:\n",
    "        j=j+1\n",
    "    if len(x)>=500 and len(x)<750:\n",
    "        k=k+1\n",
    "    if len(x)>=750 and len(x)<1000:\n",
    "        l=l+1\n",
    "    if len(x)>=1000 and len(x)<1250:\n",
    "        m=m+1\n",
    "    if len(x)>=1250 and len(x)<1500:\n",
    "        n=n+1\n",
    "    if len(x)>=1500 and len(x)<1750:\n",
    "        o=o+1\n",
    "    if len(x)>=1750 and len(x)<2000:\n",
    "        p=p+1\n",
    "    if len(x)>=2000 and len(x)<2250:\n",
    "        q=q+1\n",
    "    if len(x)>=2250 and len(x)<2500:\n",
    "        r=r+1\n",
    "    if len(x)>=2500 and len(x)<2750:\n",
    "        s=s+1\n",
    "    if len(x)>=2750 and len(x)<3000:\n",
    "        t=t+1\n",
    "    if len(x)>=3000:\n",
    "        u=u+1\n",
    "\n",
    "dfx=pd.DataFrame({'Rating Length (characters)':['0-250','250-500','500-750','750-1000','1000-1250','1250-1500','1500-1750','1750-2000','2000-2250','2250-2500','2500-2750','2750-3000','>=3000'], 'Number of Descriptions':[i,j,k,l,m,n,o,p,q,r,s,t,u]})\n",
    "dfx.plot.bar(x='Rating Length (characters)',y='Number of Descriptions',title='Distribution of Description Lengths')\n",
    "plt.tight_layout()\n",
    "plt.savefig('AvgDescriptionLength.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "micro-place",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
